{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44bea01c-0c5d-4730-b61a-89c08fc2ba83",
   "metadata": {},
   "source": [
    "# The DADA2 Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f2f73c-fd57-4543-9d9a-da5d055b0210",
   "metadata": {},
   "source": [
    "## **DADA2** (Divisive Amplicon Denoising Algorithm 2) is a widely used bioinformatics tool designed to process and analyze amplicon sequencing data, such as 16S rRNA gene sequences for bacterial communities or ITS regions for fungal communities. It is implemented primarily as an R package and offers high-resolution identification of microbial community composition.\n",
    "\n",
    "## Key Features of DADA2:\n",
    "### Error Modeling and Denoising:\n",
    "DADA2 uses a statistical model to identify and correct sequencing errors in amplicon data. This allows it to infer true biological sequences, referred to as amplicon sequence variants (ASVs), with single-nucleotide resolution, outperforming traditional OTU-based methods that cluster sequences at a fixed similarity threshold (e.g., 97%).\n",
    "\n",
    "### Amplicon Sequence Variants (ASVs):\n",
    "Instead of grouping sequences into operational taxonomic units (OTUs), DADA2 identifies exact ASVs. This provides higher sensitivity and specificity, enabling the detection of subtle biological variations and improving reproducibility across studies.\n",
    "\n",
    "## Pipeline Capabilities:\n",
    "DADA2 includes all steps necessary for processing sequencing data:\n",
    "* Quality filtering and trimming\n",
    "* Error rate learning\n",
    "* Sequence denoising\n",
    "* Merging paired-end reads\n",
    "* Chimera removal\n",
    "* Taxonomic assignment using reference databases like SILVA or UNITE.\n",
    "\n",
    "## Applications:\n",
    "DADA2 is used for microbiome studies in various fields, including environmental science, human health, and agriculture. It supports both bacterial (16S rRNA) and fungal (ITS) amplicons, making it versatile for microbial community profiling.\n",
    "\n",
    "## Integration with Other Tools:\n",
    "The output of DADA2 can be seamlessly integrated with downstream analysis tools such as Phyloseq for ecological and statistical analyses, as well as visualization of microbiome data.\n",
    "\n",
    "## Advantages Over Traditional Methods:\n",
    "* Higher resolution by distinguishing sequences differing by even a single nucleotide.\n",
    "* Improved accuracy in detecting true biological sequences while minimizing spurious results.\n",
    "* Scalability for large datasets with efficient computational performance.\n",
    "\n",
    "In summary, DADA2 is a powerful tool for high-resolution microbial community analysis, offering precise sequence inference and robust handling of sequencing errors. It has become a standard in microbiome research due to its accuracy, reproducibility, and ease of use.\n",
    "\n",
    "## Prerequisites\n",
    "* Demultiplexed paired-end FASTQ files (forward/reverse reads per sample)\n",
    "* Removed PCR primers from sequences\n",
    "* R environment with installed DADA2 package\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0a28b0-221b-4d42-82ed-141d255121bb",
   "metadata": {},
   "source": [
    "### Let's get started (Note: this is all done in RStudio):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7298c0cf-929e-44f5-ba16-33c56d7ce1e8",
   "metadata": {},
   "source": [
    "#### **Step 1**: \n",
    "\n",
    "The first thing you have to do, ***as with any R package***, is the make sure you have the dada2 package installed and loaded into your active R session. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0283096b-02ee-45a6-a626-69af42a75810",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This installs the dada2 package and it's dependencies (software components, libraries, or packages that another piece of software relies on to function correctly) to R\n",
    "if (!require(\"BiocManager\", quietly = TRUE))\n",
    "    install.packages(\"BiocManager\")\n",
    "BiocManager::install(\"dada2\", dependencies = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168562d4-f73e-4885-9340-d14c7a1e7d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This loads the dada2 package in so that way it is active during our R session. You have to \"load your libraries\" EVERY TIME you open R. \n",
    "library(dada2)\n",
    "writeLines(capture.output(sessionInfo()), file.path(\"sessionInfo.txt\")) ## This code is typically used in workflows or reports to record session details for reproducibility. By saving sessionInfo() output, others can replicate your analysis environment by knowing exactly which versions of R and packages were used. It will be named sessionInfo.txt in your working directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0e2740-04b3-41c4-a18d-efb6905577df",
   "metadata": {},
   "source": [
    "#### **Step 2**: \n",
    "Now that we have dada2 installed and running on our R session, we can start to organize our data in RStudio. We read in the names of the fastq files, and perform some string manipulation to get matched lists of the forward and reverse fastq files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328de7e2-0dbd-46ee-8285-55947c909dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "path <- \"path/to/your/fastq/files\" # Replace with the path to your data\n",
    "list.files(path) ##This will print out a list of your files and is just a safeguard to make sure you are going to be working with the right files.\n",
    "## You should be working with your cutadapt files; they will look something like: \"...R1_cut.fastq.gz\"\n",
    "\n",
    "## Here, we are organizing the forward and reverse reads into factors (fnFs, fnRs)\n",
    "## Sample name is everything before the first underscore\n",
    "fnFs <- sort(list.files(path, pattern=\"_R1_cut.fastq.gz\", full.names = TRUE)) # Forward reads\n",
    "fnRs <- sort(list.files(path, pattern=\"_R2_cut.fastq.gz\", full.names = TRUE)) # Reverse reads\n",
    "\n",
    "# Here, we are extracting sample names from our fnFs factor and putting them into their own factor, assuming filenames have format: SAMPLENAME_XXX.fastq\n",
    "sample.names <- sapply(strsplit(basename(fnFs), \"_\"), `[`, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f4db5c-4fa5-4986-aa4c-792d17e72cbc",
   "metadata": {},
   "source": [
    "#### **Step 3: Inspect and Visualize Quality**\n",
    "\n",
    "Next, we are going to check the quality of our sequencing data to decide where to trim low-quality bases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a88d91-4aaa-4afb-9779-7be2867587d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotQualityProfile(fnFs[1:6]) # Plot quality profiles for forward reads; the [1:6] means plot the quality profiles for the first 6 read files\n",
    "plotQualityProfile(fnRs[1:6]) # Plot quality profiles for reverse reads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3affd3-256f-4551-95e4-45fe9f6623a5",
   "metadata": {},
   "source": [
    "When we look at the quality profiles of our sequencing reads, we can see how the quality of each base changes across the length of the reads. Here's what the different lines on the graph mean:\n",
    "* Gray-scale heat map: Shows how often each quality score appears at each base position.\n",
    "* Green line: Represents the average (mean) quality score at each position.\n",
    "* Orange lines: Show the range of quality scores for most of the data (quartiles).\n",
    "* Red line: Indicates how many reads reach each base position. For Illumina sequencing, this line is flat because all reads are typically the same length.\n",
    "\n",
    "**Forward Reads:**\n",
    "The forward reads have good overall quality. However, toward the end of the reads (last few bases), there may be small errors that are harder to control. To avoid these errors, we tend to trim off a number of bases by truncating the forward reads at a certain position. With this data, we will trim off the last 5 bases by truncating the forward reads at position 145. This ensures we only keep high-quality data for analysis.\n",
    "\n",
    "**Reverse Reads:**\n",
    "The reverse reads are lower in quality, especially toward the end. This is normal for Illumina sequencing and not a big problem because DADA2 uses quality scores to account for errors in its analysis. However, trimming off low-quality bases where the average quality drops sharply will help improve DADA2's ability to detect rare sequences. Based on the quality profiles, we will truncate the reverse reads at position 120, where the quality starts to drop significantly.\n",
    "\n",
    "Here, we are ultimately going to be:\n",
    "* Looking for where the quality scores drop off (usually at the end of the reads).\n",
    "* Deciding on trimming lengths (```truncLen```) based on these plots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1343e378-5799-4139-abe2-a648276968e3",
   "metadata": {},
   "source": [
    "#### **Step 4: Filter and Trim Reads**\n",
    "\n",
    "Now, we are going to remove low-quality bases and filter out poor-quality reads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9acabd-3f48-463e-80ba-7f52023548e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make directory and filenames for the filtered fastqs\n",
    "filt_path <- file.path(path, \"filtered\") # Place filtered files in filtered/ subdirectory\n",
    "filtFs <- file.path(filt_path, paste0(sample.names, \"_F_filt.fastq.gz\"))\n",
    "filtRs <- file.path(filt_path, paste0(sample.names, \"_R_filt.fastq.gz\"))\n",
    "\n",
    "\n",
    "out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(150,150),\n",
    "                     maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE,\n",
    "                     compress=TRUE, multithread=TRUE) # On Windows set multithread=FALSE\n",
    "head(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e3384c-2628-4eea-88c2-68d1f09e926b",
   "metadata": {},
   "source": [
    "So, what did we do?\n",
    "\n",
    "1. filterAndTrim() function from the dada2 package to perform quality filtering and trimming on paired-end sequencing reads.\n",
    "2. processes both forward (fnFs) and reverse (fnRs) read files, outputting the filtered results to filtFs and filtRs, respectively\n",
    "3. truncLen=c(150,150): Truncates both forward and reverse reads to 150 and 150 base pairs, respectively. This removes low-quality tails that are common in Illumina sequencing\n",
    "4. maxN=0: Removes any reads with ambiguous bases (N's). No ambiguous bases allowed.\n",
    "5. maxEE=c(2,2): Sets the maximum expected errors allowed in a read to 2 for both forward and reverse reads. This is a quality filter based on the expected number of errors in a read, which is more effective than simple quality score averaging\n",
    "6. truncQ=2: Truncates reads at the first instance of a quality score of 2 or lower. Trimming low-quality tails.\n",
    "7. rm.phix=TRUE: Removes reads that match the PhiX genome, which is commonly used as a control in Illumina sequencing\n",
    "\n",
    "This step is crucial in the dada2 pipeline as it prepares the sequencing data for subsequent analysis by removing low-quality portions of reads and filtering out potentially erroneous sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75841d6-e5ba-49db-a13e-ef89b2fcd64d",
   "metadata": {},
   "source": [
    "#### **Step 5: Learn the error rates**\n",
    "\n",
    "DADA2 models the sequencing error rates to distinguish true biological sequences from errors. The ```learnErrors``` step in DADA2 is where the algorithm figures out the error patterns in your sequencing data. Every dataset has its own unique error rates, which depend on factors like the sequencing machine and experimental conditions. DADA2 builds a model of these errors to help distinguish real biological sequences from mistakes introduced during sequencing.\n",
    "\n",
    "To do this, DADA2 uses a process similar to how machine learning works:\n",
    "1. It starts with an initial guess about the error rates. This guess assumes that only the most abundant sequence is correct, and all other sequences are errors.\n",
    "2. Then, it alternates between two tasks:\n",
    "    * Estimating the error rates based on the data.\n",
    "    * Figuring out which sequences are real and which are likely errors.\n",
    "\n",
    "This back-and-forth process continues until the error rates and sequence predictions agree with each other (this is called \"convergence\").\n",
    "\n",
    "By learning the error rates directly from your data, DADA2 can accurately correct sequencing mistakes and identify true biological sequences. This step is crucial for producing high-quality results!\n",
    "\n",
    "This bit of code takes time to run. Don't worry if it takes 5-10 minutes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260687ad-51a6-4841-8370-1f92d8281fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "errF <- learnErrors(filtFs, multithread=TRUE) ## This function learns the error rates from the forward reads (filtFs). It uses machine learning to estimate the rates of different types of sequencing errors.\n",
    "errR <- learnErrors(filtRs, multithread=TRUE) ## Same with the reverse reads\n",
    "\n",
    "# Visualize error rates to confirm they are modeled correctly. This generates a plot to visualize the estimated error rates for the forward reads.\n",
    "plotErrors(errF, nominalQ=TRUE)\n",
    "plotErrors(errR, nominalQ=TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20132d5-bc31-47cd-8198-e9db3b515eb7",
   "metadata": {},
   "source": [
    "Points are the observed error rates for each consensus quality score. The black line shows the estimated error rates after convergence of the machine-learning algorithm. The red line shows the error rates expected under the nominal definition of the Q-score. Here the estimated error rates (black line) are a good fit to the observed rates (points), and the error rates drop with increased quality as expected. \n",
    "\n",
    "With this data, our error rates look reasonable. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8dae6d-4f0e-4bcf-bc17-661536d71ef8",
   "metadata": {},
   "source": [
    "#### **Step 6: Dereplication**\n",
    "\n",
    "The following code snippet performs dereplication of the filtered FASTQ files using DADA2. Dereplication is a process that combines identical sequencing reads into unique sequences and counts how many times each unique sequence appears. This step reduces redundancy and speeds up further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4573fc2-3c7c-4c67-8c80-d3454daaed89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dereplicate the filtered FASTQ files\n",
    "derepFs <- derepFastq(filtFs, verbose=TRUE)\n",
    "derepRs <- derepFastq(filtRs, verbose=TRUE)\n",
    "names(derepFs) <- sample.names\n",
    "names(derepRs) <- sample.names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb85ecf0-712d-4fd0-afd8-95c8fca961c0",
   "metadata": {},
   "source": [
    "1. **`derepFastq(filtFs, verbose=TRUE)`**:\n",
    "    - This function takes the filtered forward reads (`filtFs`) and groups identical sequences together.\n",
    "    - It outputs a list of unique sequences along with their abundances (how many times each sequence appears in the dataset).\n",
    "    - The `verbose=TRUE` option provides messages in the console to show progress and details, such as how many unique sequences were found.\n",
    "2. **`derepFastq(filtRs, verbose=TRUE)`**:\n",
    "    - Similarly, this processes the filtered reverse reads (`filtRs`) to dereplicate them.\n",
    "3. **`names(derepFs) <- sample.names`**:\n",
    "    - Assigns sample names to the dereplicated forward reads (`derepFs`). This makes it easier to track which data belongs to which sample during downstream analysis.\n",
    "4. **`names(derepRs) <- sample.names`**:\n",
    "    - Does the same for the dereplicated reverse reads (`derepRs`).\n",
    "\n",
    "**What Is Dereplication?**\n",
    "\n",
    "- Dereplication combines all identical sequences into \"unique sequences\" and records how many times each sequence appears.\n",
    "- For example:\n",
    "    - If you have 1,000 reads and 200 of them are identical, dereplication will store that sequence only once but note that it appeared 200 times.\n",
    "- This step reduces computational load during later steps like error modeling and denoising.\n",
    "\n",
    "**Why Is Dereplication Important?**\n",
    "\n",
    "1. **Reduces Redundancy**: Instead of analyzing every single read individually, only unique sequences are analyzed.\n",
    "2. **Speeds Up Analysis**: By reducing the number of sequences to process, subsequent steps like error correction and denoising are faster.\n",
    "3. **Preserves Quality Information**: DADA2 keeps track of quality scores for each unique sequence, which is crucial for accurate error modeling.\n",
    "\n",
    "**Example Output**\n",
    "\n",
    "After running this code, you might see messages like:\n",
    "\n",
    "```\n",
    "Dereplicating sequence entries in Fastq file: sample1_F_filt.fastq.gz\n",
    "## Encountered 500 unique sequences from 10,000 total reads.\n",
    "```\n",
    "\n",
    "This means that out of 10,000 reads in this sample, only 500 were unique.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd30f2e0-17bd-452e-95ae-abda5fe4915e",
   "metadata": {},
   "source": [
    "#### **Step 7: Infer the sequence variants in each sample**\n",
    "\n",
    "Here is where we are going to pull out our ASVs from our dataset. We will apply the core sample inference algorithm to the filtered,  trimmed, and dereplicated sequence data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b3331e-c4f4-48cf-a100-4adfe64a798f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dadaFs <- dada(derepFs, err=errF, multithread=TRUE)\n",
    "dadaRs <- dada(derepRs, err=errR, multithread=TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c75c5c2-24d1-4ddf-b343-51c2a1bb77a3",
   "metadata": {},
   "source": [
    "Here, we have just made a dada-class object for both our forward (```dadaFs```) and reverse (`dadaRs`) dereplicated reads. Let's take a minute to explore ```dadaFs``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451a5df2-1a4a-4acb-b302-bbb5cda37e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspecting the dada-class object returned by dada2:\n",
    "dadaFs[[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d88aeb-2bb9-40b4-adc6-96f5a4fac476",
   "metadata": {},
   "source": [
    "This is one of the most awesome parts about DADA2. It will tell you how many unique ASVs were found among our reads. Your output should look something like this:\n",
    "\n",
    "```\n",
    "dada-class: object describing DADA2 denoising results\n",
    "969 sequence variants were inferred from 28741 input unique sequences.\n",
    "Key parameters: OMEGA_A = 1e-40, OMEGA_C = 1e-40, BAND_SIZE = 16\n",
    "```\n",
    "\n",
    "Here, we see that the DADA2 algorithm inferred 969 true sequence variants from the 28,741 unique sequences in the first sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a521ffa1-58b2-4d47-bce0-14b1e54a1868",
   "metadata": {},
   "source": [
    "#### **Step 8: Merge Paired-End Reads** \n",
    "\n",
    "Now, we can combine forward and reverse reads into full-length, denoised sequences by overlapping them. Sometimes, thinking about this can seem very abstract and it's easy to get lost in the weeds. I am going to put the following explantion of merging below for those of us who really need to see something concretely in order for it to stick. \n",
    "\n",
    "**What Does Merging Mean?**\n",
    "\n",
    "In paired-end sequencing, each DNA fragment is read from both ends:\n",
    "\n",
    "- **Forward reads**: Start reading from the beginning of the fragment.\n",
    "- **Reverse reads**: Start reading from the other end and go in the reverse direction.\n",
    "\n",
    "To reconstruct the full DNA sequence, we need to combine (merge) these two reads. This is done by matching the overlapping part of the forward and reverse reads.\n",
    "\n",
    "**How Does Merging Work?**\n",
    "\n",
    "1. **Align Forward and Reverse Reads**:\n",
    "    - The algorithm aligns the forward read with the reverse read (after flipping it to its reverse complement so they match correctly).\n",
    "    - The overlapping region between the two reads is used to check if they \"agree\".\n",
    "2. **Build Full Sequences**:\n",
    "    - If the forward and reverse reads overlap by at least 12 bases (default setting) and agree perfectly in that overlap, they are merged into one complete sequence called a \"contig.\"\n",
    "3. **Adjustable Conditions**:\n",
    "    - You can change the default conditions, like requiring a longer overlap or allowing mismatches in the overlap region, by modifying the function arguments.\n",
    "\n",
    "**Why Is Merging Important?**\n",
    "\n",
    "Merging gives you the full-length denoised sequences for each DNA fragment:\n",
    "\n",
    "- Forward and reverse reads cover different parts of the fragment, so merging combines them into a single sequence.\n",
    "- This step ensures you have high-quality, accurate sequences for downstream analysis.\n",
    "\n",
    "**Key Points for Beginners**\n",
    "\n",
    "- **Overlap Requirement**: The forward and reverse reads must overlap by at least 12 bases to be merged.\n",
    "- **Perfect Match**: The overlapping region must be identical between the two reads (default setting).\n",
    "- **Output**: After merging, you get full-length sequences that are ready for further analysis.\n",
    "\n",
    "**Example**\n",
    "\n",
    "Imagine you have a DNA fragment that looks like this:\n",
    "\n",
    "```\n",
    "Full sequence: ACTGACTGACTG\n",
    "Forward read:  ACTGACTG\n",
    "Reverse read:      ACTGACTG\n",
    "```\n",
    "\n",
    "The algorithm aligns them like this:\n",
    "\n",
    "```\n",
    "Forward read: ACTGACTG\n",
    "Reverse read: ACTGACTG (reverse-complemented)\n",
    "```\n",
    "\n",
    "If they overlap perfectly (e.g., \"ACTG\"), they are merged into one complete sequence:\n",
    "\n",
    "```\n",
    "Merged sequence: ACTGACTGACTG\n",
    "```\n",
    "\n",
    "This step is crucial for reconstructing full sequences from paired-end data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7b3f75-263e-4f15-9c66-5ac16d7d314d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the denoised forward and reverse reads:\n",
    "mergers <- mergePairs(dadaFs, derepFs, dadaRs, derepRs, verbose=TRUE)\n",
    "# Inspect the merger data.frame from the first sample\n",
    "head(mergers[[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c437a53-14db-4e3c-9024-da53f3231a5c",
   "metadata": {},
   "source": [
    "So, what did we just do?\n",
    "1. We merged forward and reverse reads\n",
    "    - **`mergePairs()`**:\n",
    "    This function combines the denoised forward reads (`dadaFs`) and reverse reads (`dadaRs`) into full-length sequences. It uses the overlapping region between the forward and reverse reads to ensure they match correctly.\n",
    "    - **Inputs**:\n",
    "        - `dadaFs`: The denoised forward reads (output from the `dada()` function).\n",
    "        - `derepFs`: The dereplicated forward reads (output from the `derepFastq()` function).\n",
    "        - `dadaRs`: The denoised reverse reads.\n",
    "        - `derepRs`: The dereplicated reverse reads.\n",
    "    - **Output**:\n",
    "        - `mergers`: A list where each element corresponds to a sample. Each element contains a data frame with information about the merged sequences for that sample.\n",
    "    - **`verbose=TRUE`**:\n",
    "    This prints progress messages to the console, showing how many pairs were successfully merged.\n",
    "\n",
    "---\n",
    "\n",
    "2. Inspected the Merged Data\n",
    "\n",
    "```\n",
    "head(mergers[[1]])\n",
    "```\n",
    "\n",
    "- **`mergers[1]`**:\n",
    "Accesses the merged sequences for the first sample in the dataset. The output is a data frame containing information about each merged sequence in that sample.\n",
    "- **`head()`**:\n",
    "Displays the first few rows of this data frame.\n",
    "\n",
    "---\n",
    "\n",
    "##### **What Information Is in the Merged Data Frame?**\n",
    "\n",
    "The data frame contains details about each merged sequence, including:\n",
    "\n",
    "1. **sequence**: The full-length DNA sequence obtained by merging forward and reverse reads.\n",
    "2. **abundance**: How many times this sequence appears in the sample.\n",
    "3. **forward**: Information about the forward read (e.g., its length).\n",
    "4. **reverse**: Information about the reverse read.\n",
    "5. **nmatch**: Number of matching bases in the overlap region.\n",
    "6. **nmismatch**: Number of mismatched bases in the overlap region (should be zero if perfectly matched).\n",
    "7. **overlap**: Length of the overlap region between forward and reverse reads."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32c0d0e-90bb-4f04-b89e-3599675d17d0",
   "metadata": {},
   "source": [
    "#### **Step 9: Create an ASV Table** \n",
    "\n",
    "Next, we will construct an amplicon sequence variant (ASV) table that counts how many times each unique sequence appears in each sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6173db-0d1b-402c-a21b-2ea12f2cd7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqtab <- makeSequenceTable(mergers)\n",
    "dim(seqtab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2e0932-f9d8-4e57-adb5-8e6983e90119",
   "metadata": {},
   "source": [
    "Our `seqtab` object is a table that represents the abundance of each unique amplicon sequence variant (ASV) across all samples. The rows represent samples; each row corresponds to a different sample in your dataset. The columns represent unique sequences; each column represents a unique ASV identified across all samples. Cell values show abundance; the values in the table indicate the number of times each unique sequence (ASV) appears in each sample.\n",
    "\n",
    "Let's take a closer look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae30758-fe81-4f73-94af-464d064523a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect distribution of sequence lengths\n",
    "table(nchar(getSequences(seqtab)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0219f0-dd5f-45fa-8be6-5f9200d346d3",
   "metadata": {},
   "source": [
    "The above code will output a frequency table showing how many sequences have each length.\n",
    "\n",
    "For example, if there are 10 sequences with a length of 250 nucleotides and 5 sequences with a length of 300 nucleotides, the table will display:\n",
    "```\n",
    "250 300\n",
    " 10   5\n",
    "```\n",
    "For our data, because we did 150x2 (150 base pair, paired ends), we should not have any sequence lengths over 300! It looks like we only go up to 284, so our data looks correct!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163dbe3a-d8ca-4a2b-9095-d5a1b4e65522",
   "metadata": {},
   "source": [
    "#### **Step 10: Remove Chimeras** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c041ba66-5324-42ca-a541-e2a3010653f9",
   "metadata": {},
   "source": [
    "In the context of sequencing and molecular biology, chimeras are artificial DNA sequences that are formed when two or more different DNA fragments are incorrectly joined together during processes like PCR or library preparation. These sequences do not exist naturally and are considered artifacts.\n",
    "\n",
    "##### How Are Chimeras Formed?\n",
    "* During PCR Amplification:\n",
    "    1. Incomplete extension of a DNA strand occurs in one cycle.\n",
    "    2. The partially extended strand acts as a primer in the next cycle, binding to a different template.\n",
    "    3. This results in a hybrid sequence that combines parts of two different DNA templates.\n",
    "* During Library Preparation:\n",
    "    1. DNA fragments may recombine or concatenate inappropriately during amplification or ligation steps, creating chimeric sequences.\n",
    "\n",
    "##### Why Are Chimeras a Problem?\n",
    "**False Diversity:** Chimeras can be misinterpreted as new or unique sequences, inflating estimates of biodiversity in microbiome studies.\n",
    "\n",
    "**Taxonomic Misclassification:** They can lead to incorrect identification of organisms, especially when using marker genes like 16S rRNA for bacterial classification.\n",
    "\n",
    "**Impact on Data Quality:** Chimeras degrade the accuracy of sequencing results and can skew downstream analyses if not removed.\n",
    "\n",
    "Let's remove chimeras from our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9286c2b3-7aa6-4029-83bf-ee4cf0901c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove chimeric sequences:\n",
    "seqtab.nochim <- removeBimeraDenovo(seqtab, method=\"consensus\", multithread=TRUE, verbose=TRUE)\n",
    "dim(seqtab.nochim)\n",
    "sum(seqtab.nochim)/sum(seqtab) ##0.98 means only about 2% of the merged sequence reads are chimeras."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9185511-695e-4131-a861-59aeb7ccbce3",
   "metadata": {},
   "source": [
    "#### **Step 11: Track reads through the pipeline**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d71ca2-d656-4d63-817f-88f4b64c0f62",
   "metadata": {},
   "source": [
    "As a final check of our progress, weâ€™ll look at the number of reads that made it through each step in the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2f6730-3b52-4c59-a6ce-14b967bd3134",
   "metadata": {},
   "outputs": [],
   "source": [
    "getN <- function(x) sum(getUniques(x))\n",
    "track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtab.nochim))\n",
    "# If processing a single sample, remove the sapply calls: e.g. replace sapply(dadaFs, getN) with getN(dadaFs)\n",
    "colnames(track) <- c(\"input\", \"filtered\", \"denoisedF\", \"denoisedR\", \"merged\", \"nonchim\")\n",
    "rownames(track) <- sample.names\n",
    "head(track)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c478af43-6908-45ea-94d5-50189e622b55",
   "metadata": {},
   "source": [
    "You should get an output that looks something like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01792f3c-b047-42df-a36f-d37e38a1a387",
   "metadata": {},
   "source": [
    "```\n",
    "      input filtered denoised merged tabled nonchim\n",
    "EB745 154308   138264   136705 124519 124519  121425\n",
    "EB746 169717   156617   154639 142828 142828  140628\n",
    "EB747 146558   140275   139580 137327 137327  135657\n",
    "EB748 100209    90087    88630  83352  83352   82502\n",
    "EB749 101372    94320    92501  85759  85759   85282\n",
    "EB750  75804    69609    68095  62634  62634   61805\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453ce5be-4257-4f4a-8dd2-0c888455ba0e",
   "metadata": {},
   "source": [
    "Looks good! We kept the majority of our raw reads, and there is no over-large drop associated with any single step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7faff6c-51b2-435d-9b61-87c61afb6a52",
   "metadata": {},
   "source": [
    "#### **Step 12: Assign Taxonomy** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef38f5b9-acdb-4d26-9f80-c8febbbe0099",
   "metadata": {},
   "source": [
    "This is the last step in our DADA2 pipeline. We are now going to assign taxonomy with a database. For 16S data, I like to use the SILVA database. This is mostly because the software engineers behind DADA2 maintain reference fastas for the three most common 16S databases: **Silva**, RDP and GreenGenes2. Additionally, since we are working with samples originating from coral, we can use the Cnidarian Microbiome Database (https://figshare.com/projects/Cnidarian_Microbiome_Database/158957) that contains updated SILVA taxonomic files for characterization of cnidarian microbial communities (https://www.nature.com/articles/s41467-023-39876-6). I have provided this database with your raw sequences. \n",
    "\n",
    "To assign taxonomy, we will run the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c732e1-c965-4fcd-9303-d073853620e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxa <- assignTaxonomy(seqtab.nochim,\"~/silva_nr99_v138.1_cnidarian_train_set_.fa.gz\", multithread=TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4585968f-413e-4f45-94e6-43751c3a6f44",
   "metadata": {},
   "source": [
    "With 16S data, many ASVs (amplicon sequence variants) may have \"NA\" values in the taxonomic assignment table. NA stands for \"not assigned\" in this context, meaning the algorithm was unable to classify these sequences to a specific taxonomic level (e.g., genus or species). If these NA values are not addressed, they can interfere with downstream analyses, such as diversity metrics or taxonomic summaries.\n",
    "\n",
    "To fix the NAs, we will run: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe09679-3237-4c51-bda6-6bcc843aabd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxon <- as.data.frame(taxa,stringsAsFactors=FALSE)\n",
    "taxon$Phylum[is.na(taxon$Phylum)] <- taxon$Kingdom[is.na(taxon$Phylum)]\n",
    "taxon$Class[is.na(taxon$Class)] <- taxon$Phylum[is.na(taxon$Class)]\n",
    "taxon$Order[is.na(taxon$Order)] <- taxon$Class[is.na(taxon$Order)]\n",
    "taxon$Family[is.na(taxon$Family)] <- taxon$Order[is.na(taxon$Family)]\n",
    "taxon$Genus[is.na(taxon$Genus)] <- taxon$Family[is.na(taxon$Genus)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c83125-869a-470d-9b2c-7e349c3f32cc",
   "metadata": {},
   "source": [
    "This code is handling missing taxonomic assignments (NA) in a taxonomic table by \"filling down\" higher-level classifications into lower levels where the information is missing. So, for example:\n",
    "```\n",
    "taxon$Phylum[is.na(taxon$Phylum)] <- taxon$Kingdom[is.na(taxon$Phylum)]\n",
    "```\n",
    "This code checks for missing values (NA) in the Phylum column. If a value in the Phylum column is NA, it replaces it with the corresponding value from the Kingdom column.\n",
    "\n",
    "```\n",
    "taxon$Class[is.na(taxon$Class)] <- taxon$Phylum[is.na(taxon$Class)]\n",
    "taxon$Order[is.na(taxon$Order)] <- taxon$Class[is.na(taxon$Order)]\n",
    "taxon$Family[is.na(taxon$Family)] <- taxon$Order[is.na(taxon$Family)]\n",
    "taxon$Genus[is.na(taxon$Genus)] <- taxon$Family[is.na(taxon$Genus)]\n",
    "```\n",
    "This process is repeated for each lower taxonomic rank (Class, Order, Family, Genus). If a value in a column is NA, it gets replaced with the value from the next higher taxonomic rank.\n",
    "\n",
    "For example:\n",
    "* If Class is NA, it will be filled with the value from Phylum.\n",
    "* If Order is NA, it will be filled with the value from Class, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44856156-2da8-4fce-92bf-21f0d08ed939",
   "metadata": {},
   "source": [
    "The last step here is exporting your data into tables saved as tab deliminated text files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b484bc-ef46-4b84-8973-05aec2d111e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "write.table(taxon,file.path(\"data\", \"Ast_mixed_silva_taxa_table.txt\"),sep=\"\\t\",col.names=NA)\n",
    "write.table(seqtab.nochim, file.path(\"data\",\"Ast_mixed_silva_otu_table.txt\"),sep=\"\\t\",col.names=NA) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f217960f-eec1-43fb-b3eb-a67a3a52fc6b",
   "metadata": {},
   "source": [
    "This code is exporting two objects, taxon and seqtab.nochim, to tab-delimited text files so they can be saved and used downstream.\n",
    "\n",
    "It saves two important tables:\n",
    "* Taxonomic Table (taxon): Contains taxonomic classifications for each ASV.\n",
    "* ASV Table (seqtab.nochim): Contains counts of each ASV across samples.\n",
    "\n",
    "These tables are saved as .txt files in a folder named \"data\".\n",
    "\n",
    "The tab-delimited format (sep=\"\\t\") makes it easy to open these files in software like Excel or text editors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e101c754-287b-4987-8c10-035ce55fa351",
   "metadata": {},
   "source": [
    "### You've succesfully completed DADA2! Great work! I know it is a lot of variables, but try not to get caught in the weeds of understanding every little line of code. I have tried my best to explain everything here, but sometimes it's easy to get lost. Just take it slow and steady--learning bioinformatics is always a work in progress!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
